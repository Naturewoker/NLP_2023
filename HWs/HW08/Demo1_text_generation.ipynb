{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"provenance":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e4f722d9e6a64553a44764f83fc28f09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a412b2891020493aa67b6a6cf24bcb78","IPY_MODEL_474717556ba94ce9a42b0256b5e2eb46","IPY_MODEL_46d5477e7392448092c64255109eb36c"],"layout":"IPY_MODEL_2772fe019b4440f0a91334d678dd840b"}},"a412b2891020493aa67b6a6cf24bcb78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bbed979ff024b7f8cfea907bf2293ee","placeholder":"​","style":"IPY_MODEL_f5467ce6eae44362b81c243acd7e6013","value":"Epoch 9: 100%"}},"474717556ba94ce9a42b0256b5e2eb46":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a773478ab0e44f019b4454fbe858f3fe","max":94,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45dc65c6db7f4e029bd97765181100ca","value":94}},"46d5477e7392448092c64255109eb36c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8eac54f24664b2585cf88d9a968f1a9","placeholder":"​","style":"IPY_MODEL_84e85d0b235c4574bab6ccb8b00ca0fc","value":" 94/94 [00:01&lt;00:00, 67.64it/s, loss=0.75, v_num=23]"}},"2772fe019b4440f0a91334d678dd840b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"3bbed979ff024b7f8cfea907bf2293ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5467ce6eae44362b81c243acd7e6013":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a773478ab0e44f019b4454fbe858f3fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45dc65c6db7f4e029bd97765181100ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8eac54f24664b2585cf88d9a968f1a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84e85d0b235c4574bab6ccb8b00ca0fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"87UHAQkt5dIw"},"source":["# Text Generation Demo on Pytoch Lightning: Date Generation (One-to-Many)\n","\n","In this demo, we will show you how to create a text generator using Pytoch Lightning. This demo is inspired by Andrew Ng's deeplearning.ai course on sequence models. In this demo, we create a one-to-many RNN model for generating date in the following format: e.g. \"2002-03-11\".  "]},{"cell_type":"code","metadata":{"id":"yIz3jAIF5dI1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672741848345,"user_tz":-420,"elapsed":2727,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"eb928318-696e-40b5-98ec-3d2733452fae"},"source":["import csv\n","import numpy as np\n","import random\n","import math\n","import sys\n","\n","import torchtext\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","!pip install pytorch_lightning\n","import pytorch_lightning as pl\n","from pytorch_lightning import Trainer"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.8/dist-packages (1.8.6)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.64.1)\n","Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.13.0+cu116)\n","Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (0.11.0)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (6.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.21.6)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.4.0)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2022.11.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (21.3)\n","Requirement already satisfied: lightning-utilities!=0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (0.5.0)\n","Requirement already satisfied: tensorboardX>=2.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2.5.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.23.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch_lightning) (3.19.6)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.0.4)\n"]}]},{"cell_type":"markdown","metadata":{"id":"ULHSHW5X5dJE"},"source":["# Generate Dataset\n","We generate a toy dataset using datetime library.  The target output only comes in one format (iso format). "]},{"cell_type":"code","metadata":{"id":"km8dKUXP5dJH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672741080259,"user_tz":-420,"elapsed":6,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"82c609ef-06f1-4cf2-da86-ce2524fd55e5"},"source":["#Generating a toy dataset\n","import datetime\n","base = datetime.datetime.today()\n","base = datetime.date(base.year, base.month, base.day)\n","date_list = [base - datetime.timedelta(days=x) for x in range(0, 1500)]\n","data = [date.isoformat() for date in date_list] \n","print(data[:5])\n","maxlen=10 #all the seqeunces have 10 characters"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['2023-01-03', '2023-01-02', '2023-01-01', '2022-12-31', '2022-12-30']\n"]}]},{"cell_type":"code","metadata":{"id":"FKLIr4Od5dJP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672741080778,"user_tz":-420,"elapsed":524,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"abad8596-4ae8-4455-cd3b-b0044f0de9c6"},"source":["chars = list(set(''.join(data)))\n","data_size, vocab_size = len(data), len(chars)\n","print('There are %d lines and %d unique characters in your data.' % (data_size, vocab_size))\n","print(\"max length =\",maxlen)\n","sorted_chars= sorted(chars)\n","print(sorted_chars)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1500 lines and 11 unique characters in your data.\n","max length = 10\n","['-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"]}]},{"cell_type":"code","metadata":{"id":"YO-IDo5A5dJX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672741080780,"user_tz":-420,"elapsed":21,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"158bc703-0bf8-4b3d-bec0-6fb6839921dd"},"source":["# In this demo, we will use \"<S>\" as a seed character to initiate the sequence\n","sorted_chars.insert(0,\"<S>\") \n","print(sorted_chars)\n","vocab_size = len(sorted_chars)\n","print(vocab_size)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<S>', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n","12\n"]}]},{"cell_type":"code","source":["vocab = torchtext.vocab.vocab({})\n","for char in sorted_chars: vocab.append_token(char) "],"metadata":{"id":"1SiYQTFehkLk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(vocab.get_itos()) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQ2fXwDoi48Q","executionInfo":{"status":"ok","timestamp":1672741080781,"user_tz":-420,"elapsed":19,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"dfb3787b-16de-4219-b0f1-f8ae3d474570"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<S>', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"]}]},{"cell_type":"code","source":["print(vocab.get_stoi())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RIzWJicEjx-z","executionInfo":{"status":"ok","timestamp":1672741080781,"user_tz":-420,"elapsed":17,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"e8167aac-1876-46b1-a058-a7a3a943b3d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'7': 9, '6': 8, '8': 10, '5': 7, '9': 11, '4': 6, '-': 1, '<S>': 0, '0': 2, '1': 3, '2': 4, '3': 5}\n"]}]},{"cell_type":"markdown","metadata":{"id":"jRuFbBUx5dJr"},"source":["# Preprocessing data"]},{"cell_type":"code","metadata":{"id":"mw-BupZv5dJt"},"source":["#Encoding data\n","encoded = []\n","for line in data:\n","    line = [l for l in line] #change from string to list\n","    indices = vocab(line)\n","    encoded.append(indices)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iwKOiX5B5dJ0"},"source":["class DateDataset(Dataset):\n","  def __init__(self, data):\n","    data = [[0] + d for d in data] # add <s> at the start of every data point\n","    self.encoded = torch.LongTensor(data)\n","    \n","  def __getitem__(self, idx):\n","    return self.encoded[idx]\n","\n","  def __len__(self):\n","    return len(self.encoded)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DateDataModule(pl.LightningDataModule):\n","\n","  def __init__(self, train_data, batch_size, num_workers=0):\n","      super().__init__()\n","      self.train_data = train_data\n","      self.batch_size = batch_size\n","      self.num_workers = num_workers\n"," \n","\n","  def setup(self, stage: str):\n","    pass\n","\n","  def collate_fn(self, batch):\n","      one_hot_x = torch.stack([F.one_hot(b, num_classes=len(vocab)) for b in batch])\n","      return {\"x\": one_hot_x.float(), \"y\": torch.stack(batch)}\n","\n","  def train_dataloader(self):\n","      train_dataset = DateDataset(self.train_data)\n","      train_loader = DataLoader(train_dataset, \n","                                batch_size = self.batch_size, \n","                                shuffle = True, \n","                                collate_fn = self.collate_fn,\n","                                num_workers = self.num_workers)\n","      \n","      return train_loader\n","    \n"," "],"metadata":{"id":"Q0MWLXPzJaZp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 16\n","data_module = DateDataModule(encoded, batch_size=batch_size,num_workers=0)"],"metadata":{"id":"90IQfib5OYJI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZmXcPnNi5dJ9"},"source":["# Create & train model\n"]},{"cell_type":"code","source":["class SimpleRNN(pl.LightningModule):\n","    def __init__(self, vocab_size, learning_rate, criterion):\n","                \n","        super().__init__()\n","        self.hidden_dim = 16\n","        self.vocab_size = vocab_size\n","        self.rnn = nn.RNNCell(self.vocab_size, self.hidden_dim)\n","       \n","        self.fc = nn.Linear(self.hidden_dim, self.vocab_size)\n","        self.learning_rate = learning_rate\n","        self.criterion = criterion\n","\n","\n","    def forward(self, src, hx):\n","        hx = self.rnn(src, hx)\n","        prediction_logit = self.fc(hx)\n","        return prediction_logit, hx\n","\n","    def training_step(self, batch, batch_idx):\n","        src = batch['x'][:, :-1]\n","        target = batch['y'][:, 1:]\n","        temp = []\n","        hx = torch.randn(src.shape[0], self.hidden_dim).to(self.rnn.weight_ih.device)\n","        prediction = torch.zeros((src.shape[0], src.shape[1], self.vocab_size) ,device=hx.device)\n","        \n","        for i in range(src.shape[1]):\n","          prediction_logit, hx = self(src[:,i], hx)\n","          prediction[:, i, :] = prediction_logit\n","\n","        prediction = prediction.reshape(-1, vocab_size)\n","        target = target.reshape(-1)\n","        loss = self.criterion(prediction, target)\n","        self.log(\"train_loss\", loss)\n","        return loss\n","\n","    def configure_optimizers(self):\n","        return optim.Adam(self.parameters(), lr=self.learning_rate)"],"metadata":{"id":"YKKPBWnCJppN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","vocab_size = len(vocab)\n","lr = 0.005\n","model = SimpleRNN(vocab_size, lr, criterion)"],"metadata":{"id":"0w5KTNVpKKVr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate(model):\n","  model.eval()\n","  with torch.no_grad():\n","    output_list = []\n","    input = F.one_hot(torch.zeros([1], dtype=torch.long), num_classes=len(vocab))\n","    input = input.float()\n","    input = input.to(model.device)\n","    hx = torch.randn(input.shape[0], 16).to(model.device)\n","    for i in range(10):\n","      logit, hx = model(input, hx)\n","      prob = F.softmax(logit, dim=-1)\n","      pred = torch.multinomial(prob, 1)\n","      output = pred.item()\n","      output_list.append(output)\n","\n","      input = F.one_hot(torch.tensor([output], dtype=torch.long), num_classes=len(vocab))\n","      input = input.float()\n","      input = input.to(model.device)\n","  return \"\".join(vocab.lookup_tokens(output_list))"],"metadata":{"id":"wSpkkvTOTMRV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PrintCallback(pl.callbacks.Callback):\n","  def __init__(self, what=\"epochs\", verbose=True):\n","        self.what = what\n","        self.verbose = verbose\n","        self.state = {\"epochs\": 0, \"batches\": 0}\n","\n","  def on_train_epoch_end(self, *args, **kwargs):\n","        if self.what == \"epochs\":\n","            self.state[\"epochs\"] += 1\n","        if self.state[\"epochs\"] % 2 == 0:\n","            print('----- Generating text after Epoch: %d' % self.state[\"epochs\"])\n","            for i in range(3):\n","              print(generate(model))\n"],"metadata":{"id":"qvujPMWdPbDS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    max_epochs=10,\n","    gpus=1,\n","    callbacks=[PrintCallback()]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NeTcVNQmO3aZ","executionInfo":{"status":"ok","timestamp":1672749968948,"user_tz":-420,"elapsed":3,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"23441f94-3fef-4bf9-e5de-fe88b97e4ed4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]}]},{"cell_type":"markdown","metadata":{"id":"G4M8URGW5dK0"},"source":["# Let's train the model and generate some text"]},{"cell_type":"code","source":["for i in range(3): #before training\n","  print(generate(model))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QvtvwwwSqpAc","executionInfo":{"status":"ok","timestamp":1672749970978,"user_tz":-420,"elapsed":549,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"d9f610b4-1e6c-4e3f-d530-eb6734526f3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3<S>39908261\n","6308535277\n","2<S>92761-63\n"]}]},{"cell_type":"code","source":["trainer.fit(model, data_module)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":622,"referenced_widgets":["e4f722d9e6a64553a44764f83fc28f09","a412b2891020493aa67b6a6cf24bcb78","474717556ba94ce9a42b0256b5e2eb46","46d5477e7392448092c64255109eb36c","2772fe019b4440f0a91334d678dd840b","3bbed979ff024b7f8cfea907bf2293ee","f5467ce6eae44362b81c243acd7e6013","a773478ab0e44f019b4454fbe858f3fe","45dc65c6db7f4e029bd97765181100ca","b8eac54f24664b2585cf88d9a968f1a9","84e85d0b235c4574bab6ccb8b00ca0fc"]},"id":"cTVJ8ZGFO5W3","executionInfo":{"status":"ok","timestamp":1672749986947,"user_tz":-420,"elapsed":14112,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"3cfae3cf-03ca-45e1-d9a1-0fe0d7029d11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name      | Type             | Params\n","-----------------------------------------------\n","0 | rnn       | RNNCell          | 480   \n","1 | fc        | Linear           | 204   \n","2 | criterion | CrossEntropyLoss | 0     \n","-----------------------------------------------\n","684       Trainable params\n","0         Non-trainable params\n","684       Total params\n","0.003     Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4f722d9e6a64553a44764f83fc28f09"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----- Generating text after Epoch: 2\n","2029-11-21\n","2021-02-11\n","2019-06-14\n","----- Generating text after Epoch: 4\n","2022-10-04\n","2011-08-04\n","2021-12-17\n","----- Generating text after Epoch: 6\n","2022-02-15\n","2020-11-27\n","2022-06-05\n","----- Generating text after Epoch: 8\n","2062-07-27\n","2019-07-14\n","2019-01-15\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"]},{"output_type":"stream","name":"stdout","text":["----- Generating text after Epoch: 10\n","2022-07-25\n","2021-02-03\n","2021-11-21\n"]}]},{"cell_type":"code","source":["for i in range(10):\n","  print(generate(model))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voYlHp7cWyAk","executionInfo":{"status":"ok","timestamp":1672749927530,"user_tz":-420,"elapsed":4,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"427fb7f9-00b0-4f4d-d345-5382571b19a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-09-32\n","2022-01-04\n","2019-10-12\n","2019-08-27\n","2020-02-25\n","2020-03-10\n","2019-12-02\n","2019-03-21\n","2022-10-24\n","2019-10-22\n"]}]},{"cell_type":"code","metadata":{"id":"uhpse2Wl1-QR"},"source":[],"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"provenance":[],"collapsed_sections":["EB0ipHig9gOm","cEyHEfFt9gO9","Qv475_JS9gQY","ePf2CDQb9gQ-"]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7fc60d1e6a914c548953fe71aefa5aa6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd7ad91760ec44bebd5107ee6d766ee5","IPY_MODEL_767f58bacbb64372bc749d0c2ac825b6","IPY_MODEL_ea414562fb9a462e810860062f3c3da4"],"layout":"IPY_MODEL_2dd5b6d9413642e6b689a973cdad15f0"}},"fd7ad91760ec44bebd5107ee6d766ee5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0424477e05764ec2b73c8d0d87cf7d13","placeholder":"​","style":"IPY_MODEL_960ff2dbc1d64f4ba47ceb63cd6dd66d","value":"Epoch 9: 100%"}},"767f58bacbb64372bc749d0c2ac825b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0762317c1f0546acb3e99231a51d0988","max":938,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59cf4f9e94564b8381c523d0c54986dc","value":938}},"ea414562fb9a462e810860062f3c3da4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_267e116cb5d3421696efa75e59439085","placeholder":"​","style":"IPY_MODEL_a890f7ab1654487ea700b3647182ddb7","value":" 938/938 [00:21&lt;00:00, 43.26it/s, loss=0.0602, v_num=0]"}},"2dd5b6d9413642e6b689a973cdad15f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"0424477e05764ec2b73c8d0d87cf7d13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"960ff2dbc1d64f4ba47ceb63cd6dd66d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0762317c1f0546acb3e99231a51d0988":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59cf4f9e94564b8381c523d0c54986dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"267e116cb5d3421696efa75e59439085":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a890f7ab1654487ea700b3647182ddb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90058c7f5dc54114829e85dd26f363bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb387ef95a69444eaf50b1df1e393b8e","IPY_MODEL_cae16d6baf734acdbf4bae747a781e86","IPY_MODEL_b9246349debb42ec86730a516057d076"],"layout":"IPY_MODEL_34deafb43e7849a597f6dc3ca6872f98"}},"cb387ef95a69444eaf50b1df1e393b8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b1190b33419472f930d70a0371923b6","placeholder":"​","style":"IPY_MODEL_97fb4df214294105a67f52470152660a","value":"Predicting DataLoader 0: 100%"}},"cae16d6baf734acdbf4bae747a781e86":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18e2b58c44d9473dad716f9773438ef4","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff419ef0256c4773b14d6bee82522843","value":8}},"b9246349debb42ec86730a516057d076":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34aac3f59c814d35b33a2ca7348674d6","placeholder":"​","style":"IPY_MODEL_0133b337814445fc89504402459df25e","value":" 8/8 [00:00&lt;00:00, 73.05it/s]"}},"34deafb43e7849a597f6dc3ca6872f98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"8b1190b33419472f930d70a0371923b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97fb4df214294105a67f52470152660a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18e2b58c44d9473dad716f9773438ef4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff419ef0256c4773b14d6bee82522843":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34aac3f59c814d35b33a2ca7348674d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0133b337814445fc89504402459df25e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Part 1 : Additive Attention from scratch"],"metadata":{"id":"0u4d0nVRMVgG"}},{"cell_type":"markdown","metadata":{"id":"EB0ipHig9gOm"},"source":["## Attention Mechanism Demo on Pytorch: Machine Translation Example (Many-to-Many, encoder-decoder)\n","\n","In this demo, we will show you how to create a machine translator using Pytorch. This demo is inspired by Andrew Ng's deeplearning.ai course on sequence models. (Programming Assignment: Neural Machine Translation with Attention)    In this demo, we create a machine translator to translate dates in various formats  into dates in an ISO format. "]},{"cell_type":"code","metadata":{"id":"3_clL4w89gOt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672980070170,"user_tz":-420,"elapsed":15225,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"e63e2785-a0e4-4dab-80cd-1e156549766c"},"source":["%matplotlib inline\n","\n","import torchtext\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","!pip install pytorch_lightning\n","import pytorch_lightning as pl\n","from pytorch_lightning import Trainer\n","\n","import random\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_lightning\n","  Downloading pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.3/800.3 KB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.21.6)\n","Collecting torchmetrics>=0.7.0\n","  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting lightning-utilities!=0.4.0,>=0.3.0\n","  Downloading lightning_utilities-0.5.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (6.0)\n","Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.13.0+cu116)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2022.11.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (21.3)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.64.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.4.0)\n","Collecting tensorboardX>=2.2\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.25.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch_lightning) (3.19.6)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.0)\n","Installing collected packages: tensorboardX, torchmetrics, lightning-utilities, pytorch_lightning\n","Successfully installed lightning-utilities-0.5.0 pytorch_lightning-1.8.6 tensorboardX-2.5.1 torchmetrics-0.11.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"cEyHEfFt9gO9"},"source":["## Generate Dataset\n","We generate a toy dataset using datetime library.  A target output only comes in one format (iso format), while there are three different date format for an input."]},{"cell_type":"code","metadata":{"id":"MWRgqvwY9gO_"},"source":["#Generating a toy dataset\n","import datetime\n","base = datetime.datetime.today()\n","base = datetime.date(base.year, base.month, base.day)\n","date_list = [base - datetime.timedelta(days=x) for x in range(0, 15000)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KrNHzgFy9gPI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672980070172,"user_tz":-420,"elapsed":17,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"0613b822-44d1-4b49-da53-0e9f99998288"},"source":["target_date_list = [date.isoformat() for date in date_list] \n","print(target_date_list[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-06\n"]}]},{"cell_type":"code","metadata":{"id":"GT7V4FJL9gPR"},"source":["from random import randint\n","random.seed(42)\n","input_date_list = list()\n","for date in date_list:\n","    random_num = randint(0, 2)\n","    if random_num == 0:\n","        input_date_list.append(date.strftime(\"%d/%m/%y\"))#\"11/03/02\"\n","    elif random_num == 1:\n","        input_date_list.append(date.strftime(\"%A %d %B %Y\")) #\"Monday 11 March 2002\"\n","    elif random_num == 2: \n","        input_date_list.append(date.strftime(\"%d %B %Y\")) #\"11 March 2002\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"isfXKy2y9gPZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672980070172,"user_tz":-420,"elapsed":15,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"845c29c3-f5b4-4d0c-d92b-7f73526b3282"},"source":["for input_sample, target_sample in zip(input_date_list[0:10],target_date_list[0:10]):\n","    print(input_sample,target_sample)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["06 January 2023 2023-01-06\n","05/01/23 2023-01-05\n","04/01/23 2023-01-04\n","03 January 2023 2023-01-03\n","Monday 02 January 2023 2023-01-02\n","01/01/23 2023-01-01\n","31/12/22 2022-12-31\n","30/12/22 2022-12-30\n","29 December 2022 2022-12-29\n","28/12/22 2022-12-28\n"]}]},{"cell_type":"code","metadata":{"id":"7KndjKsS9gPg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672980070172,"user_tz":-420,"elapsed":13,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"58edf39c-aa74-4562-f60d-b76dc840291b"},"source":["#Preprocessing\n","input_chars = list(set(''.join(input_date_list)))\n","output_chars = list(set(''.join(target_date_list)))\n","\n","# +1 for padding\n","data_size, vocab_size = len(input_date_list), len(input_chars)+1 \n","output_vocab_size = len(output_chars)+1\n","\n","print('There are %d lines and %d unique characters in your input data.' % (data_size, vocab_size))\n","maxlen = len( max(input_date_list, key=len)) #max input length"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 15000 lines and 42 unique characters in your input data.\n"]}]},{"cell_type":"code","metadata":{"id":"3K-0kaUH9gPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672980070174,"user_tz":-420,"elapsed":14,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"674b3a69-52eb-4dd4-ebee-be841211d4b8"},"source":["print(\"Max input length:\", maxlen)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Max input length: 27\n"]}]},{"cell_type":"code","source":["sorted_chars= sorted(input_chars)\n","sorted_output_chars= sorted(output_chars)\n","sorted_chars.insert(0,\"<PAD>\") #PADDING for input\n","sorted_output_chars.insert(0,\"<PAD>\") #PADDING for output\n","\n","#input vocab\n","input_vocab = torchtext.vocab.vocab({})\n","for char in sorted_chars: input_vocab.append_token(char) \n","\n","#output vocab\n","output_vocab = torchtext.vocab.vocab({})\n","for char in sorted_output_chars: output_vocab.append_token(char) "],"metadata":{"id":"YaP2TKsD1UOn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(sorted(input_vocab.get_stoi().items(), key=lambda item: item[1]))\n","print(sorted(output_vocab.get_stoi().items(), key=lambda item: item[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ulW7bT9V1pS9","executionInfo":{"status":"ok","timestamp":1672980070174,"user_tz":-420,"elapsed":12,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"ce30a9ec-694e-4f9f-ad83-bd5a8defd738"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('<PAD>', 0), (' ', 1), ('/', 2), ('0', 3), ('1', 4), ('2', 5), ('3', 6), ('4', 7), ('5', 8), ('6', 9), ('7', 10), ('8', 11), ('9', 12), ('A', 13), ('D', 14), ('F', 15), ('J', 16), ('M', 17), ('N', 18), ('O', 19), ('S', 20), ('T', 21), ('W', 22), ('a', 23), ('b', 24), ('c', 25), ('d', 26), ('e', 27), ('g', 28), ('h', 29), ('i', 30), ('l', 31), ('m', 32), ('n', 33), ('o', 34), ('p', 35), ('r', 36), ('s', 37), ('t', 38), ('u', 39), ('v', 40), ('y', 41)]\n","[('<PAD>', 0), ('-', 1), ('0', 2), ('1', 3), ('2', 4), ('3', 5), ('4', 6), ('5', 7), ('6', 8), ('7', 9), ('8', 10), ('9', 11)]\n"]}]},{"cell_type":"code","metadata":{"id":"8Q0XsxhL9gP2"},"source":["m=15000\n","Tx=maxlen\n","Ty=10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PvKOfVnc9gP-"},"source":["X = []\n","for line in input_date_list:\n","    line = [l for l in line] #change from string to list\n","    X.append(torch.tensor(input_vocab(line)))\n","Y = []\n","for line in target_date_list:\n","    line = [l for l in line] #change from string to list\n","    Y.append(torch.tensor(output_vocab(line)))\n","\n","X = nn.utils.rnn.pad_sequence(X, batch_first = True) "],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"trjH1DiZ3yyS","executionInfo":{"status":"ok","timestamp":1672980070960,"user_tz":-420,"elapsed":10,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"3e259950-2da9-4061-bb9e-8fc76cb4db1f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([15000, 27])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["class DateDataset(Dataset):\n","  def __init__(self, X, y):\n","    self.encoded = X.long()\n","    self.label = torch.stack(y).long()\n","    \n","  def __getitem__(self, idx):\n","    return {\"x\" :self.encoded[idx], \"y\":self.label[idx]}\n","\n","  def __len__(self):\n","    return len(self.encoded)"],"metadata":{"id":"9khoV30W33US"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DateDataModule(pl.LightningDataModule):\n","\n","  def __init__(self, train_data, y, batch_size, num_workers=0):\n","      super().__init__()\n","      self.train_data = train_data\n","      self.y = y\n","      self.batch_size = batch_size\n","      self.num_workers = num_workers\n"," \n","\n","  def setup(self, stage: str):\n","    pass\n","\n","  def collate_fn(self, batch):\n","      one_hot_x = torch.stack([F.one_hot(b[\"x\"], num_classes=len(input_vocab)) for b in batch])\n","      return {\"x\": one_hot_x.float(), \"y\": torch.stack([b[\"y\"] for b in batch])}\n","\n","  def train_dataloader(self):\n","      train_dataset = DateDataset(self.train_data, self.y)\n","      train_loader = DataLoader(train_dataset, \n","                                batch_size = self.batch_size, \n","                                shuffle = True, \n","                                collate_fn = self.collate_fn,\n","                                num_workers = self.num_workers)\n","      \n","      return train_loader\n"],"metadata":{"id":"Z1ONZO0S3_qt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 16\n","data_module = DateDataModule(X, Y, batch_size=batch_size,num_workers=0)"],"metadata":{"id":"vHtxahO54IfJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UFYhwzdj9gQG"},"source":["## Attention Mechanism\n","![attn_mech](https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/attn_mech.png)"]},{"cell_type":"code","source":["def one_step_attention(h, s_prev, linear_1, linear_2):\n","    #h.shape = batch, seq_len, hidden_dim\n","    #s_prev.shape = batch, hidden_dim\n","    # #linear_1 and linear_2 are linear layers in the model\n","    s_prev = s_prev.unsqueeze(1).repeat((1, h.shape[1], 1))\n","    concat = torch.cat([h, s_prev], dim=-1) #concat.shape = batch, seq_len, hidden_dim*2\n","\n","    #Attention function### \n","    e = F.tanh(linear_1(concat))\n","    energies = F.relu(linear_2(e))\n","    # calculate attention_scores (softmax)\n","    attention_scores = F.softmax(energies, dim=1)\n","    # calculate a context vector\n","    temp = torch.mul(attention_scores, h)\n","    context = torch.sum(temp,dim=1)\n","\n","    return context\n"],"metadata":{"id":"ry5bLZjX4pwX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qv475_JS9gQY"},"source":["## The model\n","![rnn_model](https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/rnn_date.png)"]},{"cell_type":"code","source":["class AttentionModel(pl.LightningModule):\n","    def __init__(self, learning_rate, criterion):\n","                \n","        super().__init__()\n","        self.n_h = 32 #hidden dimensions for encoder \n","        self.n_s = 64 #hidden dimensions for decoder\n","\n","        self.learning_rate = learning_rate\n","        self.criterion = criterion\n","\n","        #encoder\n","        bidirection = True\n","        self.num_directions = 2 if bidirection else 1\n","        self.lstm = nn.LSTM(len(input_vocab), self.n_h, bidirectional=bidirection, batch_first=True)\n","        #decoder \n","        self.decoder_lstm_cell = nn.LSTMCell(self.n_s, self.n_s)\n","        self.output_layer = nn.Linear(self.n_s, len(output_vocab))\n","        #attention\n","        self.fc1 = nn.Linear(self.n_h*2*self.num_directions, self.n_h)\n","        self.fc2 = nn.Linear(self.n_h, 1)\n","\n","    def forward(self, src):\n","        lstm_out, _ = self.lstm(src) \n","        \n","        decoder_s = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n","        decoder_c = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n","\n","        prediction = torch.zeros((src.shape[0], Ty, len(output_vocab))).to(self.decoder_lstm_cell.weight_ih.device)\n","        #Iterate for Ty steps (Decoding)\n","        for t in range(Ty):\n","\n","            #Perform one step of the attention mechanism to calculate the context vector at timestep t\n","            context = one_step_attention(lstm_out, decoder_s, self.fc1, self.fc2)\n","            # Feed the context vector to the decoder LSTM cell\n","            decoder_s, decoder_c = self.decoder_lstm_cell(context, (decoder_s, decoder_c))\n","              \n","            # Pass the decoder hidden output to the output layer (softmax)\n","            out = self.output_layer(decoder_s)\n","            \n","            # Append an output list with the current output\n","            prediction[:, t] = out\n","        return prediction\n","\n","    def training_step(self, batch, batch_idx):\n","        src = batch['x']\n","        target = batch['y']\n","        prediction = self(src)\n","        prediction = prediction.reshape(-1, len(output_vocab))\n","        target = target.reshape(-1)\n","        loss = self.criterion(prediction, target)\n","        self.log(\"train_loss\", loss)\n","        return loss\n","\n","    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n","        src = batch['x']\n","        with torch.no_grad():\n","          prediction = self(src)\n","          prediction = F.softmax(prediction, dim=-1)\n","          prediction = torch.argmax(prediction, dim=-1)\n","          for pred in prediction:\n","            print(\"\".join(output_vocab.lookup_tokens(pred.cpu().numpy())))\n","\n","    def configure_optimizers(self):\n","        return optim.Adam(self.parameters(), lr=self.learning_rate)"],"metadata":{"id":"C0PIR2vV4MLo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","lr = 0.01\n","model = AttentionModel(lr, criterion)"],"metadata":{"id":"d6VHTvyoFuxh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    max_epochs=10,\n","    gpus=1,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tYColP-nGW5q","executionInfo":{"status":"ok","timestamp":1672980070962,"user_tz":-420,"elapsed":9,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"c0babe45-e665-4223-ab94-d7e0508bc9a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n","  rank_zero_deprecation(\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]}]},{"cell_type":"code","source":["trainer.fit(model, data_module)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379,"referenced_widgets":["7fc60d1e6a914c548953fe71aefa5aa6","fd7ad91760ec44bebd5107ee6d766ee5","767f58bacbb64372bc749d0c2ac825b6","ea414562fb9a462e810860062f3c3da4","2dd5b6d9413642e6b689a973cdad15f0","0424477e05764ec2b73c8d0d87cf7d13","960ff2dbc1d64f4ba47ceb63cd6dd66d","0762317c1f0546acb3e99231a51d0988","59cf4f9e94564b8381c523d0c54986dc","267e116cb5d3421696efa75e59439085","a890f7ab1654487ea700b3647182ddb7"]},"id":"rD1UelkcGZSh","executionInfo":{"status":"ok","timestamp":1672980307060,"user_tz":-420,"elapsed":236106,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"9162873b-c144-4715-9056-723dfb366df8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name              | Type             | Params\n","-------------------------------------------------------\n","0 | criterion         | CrossEntropyLoss | 0     \n","1 | lstm              | LSTM             | 19.5 K\n","2 | decoder_lstm_cell | LSTMCell         | 33.3 K\n","3 | output_layer      | Linear           | 780   \n","4 | fc1               | Linear           | 4.1 K \n","5 | fc2               | Linear           | 33    \n","-------------------------------------------------------\n","57.7 K    Trainable params\n","0         Non-trainable params\n","57.7 K    Total params\n","0.231     Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fc60d1e6a914c548953fe71aefa5aa6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"]}]},{"cell_type":"markdown","metadata":{"id":"ePf2CDQb9gQ-"},"source":["## Let's do some \"translation\""]},{"cell_type":"code","source":["EXAMPLES = ['Monday 15 March 2022', '3 May 1999', '05 October 2009', '30 August 2016', '11 July 2000', 'Saturday 19 May 2018', '3 March 2001', '1 March 2001']\n","predict_data = []\n","for line in EXAMPLES:\n","    line = [l for l in line] #change from string to list\n","    predict_data.append(torch.tensor(input_vocab(line)))\n","\n","print(len(predict_data))    \n","def collate_fn(batch):\n","    one_hot_x = torch.stack([F.one_hot(b[\"x\"], num_classes=len(input_vocab)) for b in batch])\n","    return {\"x\": one_hot_x.float()}\n","\n","predict_data = nn.utils.rnn.pad_sequence(predict_data, batch_first = True)\n","predict_dataset = DateDataset(predict_data, [torch.tensor(0)]*len(predict_data))\n","predict_loader = DataLoader(predict_dataset, \n","                          batch_size = 1, \n","                          shuffle = False, \n","                          collate_fn = collate_fn,\n","                          num_workers = 0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6stNACsUP9h-","executionInfo":{"status":"ok","timestamp":1672980307061,"user_tz":-420,"elapsed":20,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"88b336ef-22d4-4d13-e217-7a9f2d38ef96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["8\n"]}]},{"cell_type":"code","source":["trainer.predict(model, predict_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257,"referenced_widgets":["90058c7f5dc54114829e85dd26f363bb","cb387ef95a69444eaf50b1df1e393b8e","cae16d6baf734acdbf4bae747a781e86","b9246349debb42ec86730a516057d076","34deafb43e7849a597f6dc3ca6872f98","8b1190b33419472f930d70a0371923b6","97fb4df214294105a67f52470152660a","18e2b58c44d9473dad716f9773438ef4","ff419ef0256c4773b14d6bee82522843","34aac3f59c814d35b33a2ca7348674d6","0133b337814445fc89504402459df25e"]},"id":"LsN71S9uQ9wo","executionInfo":{"status":"ok","timestamp":1672980307062,"user_tz":-420,"elapsed":19,"user":{"displayName":"Kasidis Kanwatchara","userId":"16282887364982711910"}},"outputId":"7b47a099-671c-4af8-dc8c-9dd065481632"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 938it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90058c7f5dc54114829e85dd26f363bb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["2022-03-15\n","1999-05-33\n","2009-10-05\n","2016-08-30\n","2000-07-11\n","2011-05-19\n","2001-03-33\n","2001-03-11\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/epoch/prediction_epoch_loop.py:134: UserWarning: predict returned None if it was on purpose, ignore this warning...\n","  self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\n"]},{"output_type":"execute_result","data":{"text/plain":["[None, None, None, None, None, None, None, None]"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":[],"metadata":{"id":"DxIITTk_MNDV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PART 2"],"metadata":{"id":"Hqk8K5AXMNmG"}},{"cell_type":"code","metadata":{"id":"20ZzVIPCAXvG"},"source":["#ADD MULTIHEAD ATTENTION\n","# MULTIHEAD ATTENTION is self attention. this example is encoder-decoder attention\n","# but encoder-decoder attention not available in pytorch"],"execution_count":null,"outputs":[]}]}